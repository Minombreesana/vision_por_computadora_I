{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "changed-samba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "equal-ethnic",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = './material_TPs/TP7/vtest.avi'\n",
    "cap = cv.VideoCapture(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "skilled-recall",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = 13\n",
    "# tiempo en segundos\n",
    "time = 20\n",
    "\n",
    "total_frames = cap.get(cv.CAP_PROP_FRAME_COUNT) \n",
    "fps = int(cap.get(cv.CAP_PROP_FPS)) \n",
    "seconds = int(total_frames / fps)\n",
    "actualization = np.arange(0,seconds,time) \n",
    "\n",
    "for i in actualization:\n",
    "    \n",
    "        frames = cap.get(cv.CAP_PROP_FRAME_COUNT) * np.random.uniform(size=n)\n",
    "        samples = []\n",
    "        \n",
    "        for i in frames:\n",
    "            \n",
    "            cap.set(cv.CAP_PROP_POS_FRAMES, i)\n",
    "            ret, frame = cap.read()\n",
    "            samples.append(frame)\n",
    "        \n",
    "        med_frame = np.median(samples, axis=0).astype(dtype=np.uint8)\n",
    "        gray_med = cv.cvtColor(med_frame, cv.COLOR_BGR2GRAY)\n",
    "        \n",
    " \n",
    "#cv.imshow('frame', med_frame)\n",
    "cv.waitKey(0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "leading-coverage",
   "metadata": {},
   "source": [
    "Adjunto captura del background estimado por mediana\n",
    "\n",
    "<img title=\"a title\" alt=\"Alt text\" src=\"./material_TPs/TP7/background.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "missing-exchange",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap.set(cv.CAP_PROP_POS_FRAMES, 0)\n",
    "ret = True\n",
    "\n",
    "while (cap.isOpened()):\n",
    "    ret, frame = cap.read()\n",
    "    cap.set(cv.CAP_PROP_FPS, 30)\n",
    "    \n",
    "    if ret:\n",
    "        frame_gray = cv.cvtColor(frame, cv.COLOR_BGR2GRAY)\n",
    "        diff = cv.absdiff(frame_gray, gray_med)\n",
    "        th, mask = cv.threshold(diff, 30, 255, cv.THRESH_BINARY)\n",
    "            \n",
    "    cv.imshow('diferencia', mask)\n",
    "    cv.imshow('frame', frame)\n",
    "    if (cv.waitKey(2) == ord('s')):\n",
    "        break\n",
    "    \n",
    "cap.release()\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "first-daniel",
   "metadata": {},
   "source": [
    "### Comparaci칩n con Mezcla de Gaussianas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "floating-friend",
   "metadata": {},
   "source": [
    "Dejo ac치 el link del video de comparaci칩n de mezcla de gaussianas con el resultado del algoritmo.\n",
    "\n",
    "https://www.youtube.com/watch?v=V3AXl14UFsc\n",
    "\n",
    "La conclusi칩n es que tiene mucho menos ruido que el GMM porque al hacer la diferencia con la mediana, hace un efecto parecido al filtro de mediana que elimina ruido salt and pepper, que es el ruido que se nota en la hecha con GMM. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "legendary-frank",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cv_tp",
   "language": "python",
   "name": "cv_tp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
